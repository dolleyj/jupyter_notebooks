{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Descriptions of uploader classes and methods\n",
    "'''\n",
    "1) Determine FileType: xlsx, mex, h5ad, h5_from_10x\n",
    "2) Based on filetype, create a Class object that is specific to the FileType\n",
    "    - different filetypes require different processing and handling\n",
    "    - class - xlsx\n",
    "        - method - open and read excel file into an AnnData object\n",
    "            - 1st option: use scanpy's read_excel(file)\n",
    "                - Can't do. scanpy uses AnnData lib to read the excel file. AnnData's read.py is limited\n",
    "                  to reading 1 sheet, which becomes '.X' of the AnnData object\n",
    "                - Links:\n",
    "                    scanpy - https://scanpy.readthedocs.io/en/latest/api/scanpy.api.read_excel.html#scanpy.api.read_excel\n",
    "                    AnnData - https://github.com/theislab/anndata/blob/master/anndata/readwrite/read.py#L40\n",
    "            - 2nd option: use pandas.read_excel to import all sheets\n",
    "            - 3rd option: use python module (xlrd?) to parse out info\n",
    "        - method? - validation checks\n",
    "            - check which sheets are present.\n",
    "                - required - 'expression' and 'observation'\n",
    "                - optional - 'genes'\n",
    "            - validate # observations in 'observation' sheet equals # observations in 'expression' sheet\n",
    "            - validate observation names in 'observation' sheet equal those in 'expression' sheet\n",
    "            - If 'genes' sheet present, validate # genes in 'genes' sheet equals # genes in 'expression' sheet\n",
    "            - If 'genes' sheet present, validate gene names in 'genes' sheet equal those in 'expression' sheet\n",
    "            - check 'expression' contains no strings in matrix\n",
    "        - method - validate gene symbols / ensembl ids with gEAR MySQL\n",
    "            - new Global function\n",
    "        - method - calculate averages, standard_deviations, p-values from replicates\n",
    "            - ? TODO ?: Add FDR and standard_errors ?\n",
    "            -use new Global functions:\n",
    "                - calc_average()\n",
    "                - calc_std_dev()\n",
    "                - calc_pval()\n",
    "        - method - calculate coloring values\n",
    "            - gene based color & abs color\n",
    "            - tissue based color & abs color\n",
    "            - dataset based color & abs color\n",
    "    - class - mex\n",
    "    - class - h5ad\n",
    "    - class - h5_from_10x\n",
    "3) Handle unstructured metadata (xlsx, txt, or json?)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.upload_dataset.<locals>.Excel at 0x7fb0d61d6f98>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "#reference: http://python-3-patterns-idioms-test.readthedocs.io/en/latest/Factory.html#preventing-direct-creation\n",
    "\n",
    "class FileType(object):\n",
    "    filetypes = []\n",
    "    \n",
    "def upload_dataset(filetype):\n",
    "    #This factory nests the dataset filetype classes. Preventing them from being directly called\n",
    "    # dataset = upload_dataset('excel')\n",
    "    #   creates an Excel class object which now can be processed for uploading\n",
    "    class Excel(FileType):\n",
    "        def _read_file(self):\n",
    "            # 3 options: \n",
    "            #   1. request scanpy writers to add multiple sheets to scanpy.read_excel\n",
    "            #   2. use pandas.read_excel to import all sheets (3 separate DataFrames I think)\n",
    "            #   3. suboptimal - use python module to parse out info (xlrd?)\n",
    "\n",
    "            # NOTE: Depending on the end format of _read_file(), will determine a lot \n",
    "            #       of how this work and reusable by other FileType objects (Mex, H5ad, H510x) \n",
    "            validate_dataset(self)\n",
    "            # RETURNS AnnData object or pandas dataframe\n",
    "            pass\n",
    "\n",
    "        def _add_calculated_values(self):\n",
    "            #calculate statistical values\n",
    "            calc_average()\n",
    "            calc_pval()\n",
    "            calc_std_dev()\n",
    "            calc_std_err() #TODO?\n",
    "            calc_fdr() #TODO?\n",
    "            pass\n",
    "\n",
    "        def _add_color_values(self):\n",
    "            #calculate raw and absolute coloring\n",
    "            get_color_gene()\n",
    "            get_color_tissue()\n",
    "            get_color_dataset()\n",
    "            get_color_abs_gene()\n",
    "            get_color_abs_tissue()\n",
    "            get_color_abs_dataset()\n",
    "\n",
    "        pass\n",
    "\n",
    "    class Mex(FileType):\n",
    "        pass\n",
    "    class H5ad(FileType):\n",
    "        pass\n",
    "    class H510x(FileType):\n",
    "        pass\n",
    "    if filetype == \"excel\": return Excel()\n",
    "    if filetype == \"mex\": return Mex()\n",
    "    if filetype == \"h5ad\": return H5ad()\n",
    "    if filetype == \"hdf5\": return H510x()\n",
    "    assert 0, \"Do not recognize file type given: \" + filetype\n",
    "\n",
    "\n",
    "\n",
    "# ----- helper functions ----- #\n",
    "# How these are performed depends on whether UploadFileTypeObject is AnnData vs pandas DataFrames\n",
    "\n",
    "def validate_dataset(UploadFileTypeObject):\n",
    "    # Runs validation checks:\n",
    "    #   1. 'expression' and 'observation' sheets present? Is optional sheet 'genes' present?\n",
    "    #   2. # rows in 'observation' == # columns in 'expression'\n",
    "    #   3. names in 'observation' == names in 'expression'\n",
    "    #   4. # rows in 'genes' == # rows in 'expression' (If 'genes' present)\n",
    "    #   5. name in 'genes' == names in 'expression' (If 'genes' present)\n",
    "    #   6. 'expression' sheet lacks string values\n",
    "    # Raise Error if any above tests fail\n",
    "    pass\n",
    "        \n",
    "def validate_genes(UploadFileTypeObject):\n",
    "    # After the data file is loaded as a object:\n",
    "    #   1. Connect to gEAR MySQL and create a cache of genes (denoting primary and secondary symbols)\n",
    "    #   2. Use cached genes to generate a list of genes that:\n",
    "    #       A. Are not in the database\n",
    "    #       B. Are duplicated secondary gene symbols. The primary is already present.\n",
    "    #   3. Return list to user of what genes were skipped \n",
    "        \n",
    "    # optional: This function could also remove those not found/skipped genes? \n",
    "    pass\n",
    "\n",
    "def calc_average():\n",
    "    pass\n",
    "\n",
    "def calc_pval():\n",
    "    pass\n",
    "\n",
    "def calc_std_dev():\n",
    "    pass\n",
    "\n",
    "def calc_std_err():\n",
    "    #TODO: Are we doing this?\n",
    "    # was requested by Seth a ways back\n",
    "    pass\n",
    "def calc_fdr():\n",
    "    #TODO: Are we doing this?\n",
    "    # corrected pvalue\n",
    "    pass\n",
    "\n",
    "def get_color_gene():\n",
    "    pass\n",
    "def get_color_tissue():\n",
    "    pass\n",
    "def get_color_dataset():\n",
    "    pass\n",
    "\n",
    "def get_color_abs_gene():\n",
    "    pass\n",
    "def get_color_abs_tissue():\n",
    "    pass    \n",
    "def get_color_abs_dataset():\n",
    "    pass\n",
    "\n",
    "# Create an excel object\n",
    "x = upload_dataset('excel')\n",
    "x"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
